wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo
yum install apache-maven
hadoop fs -mkdir -p /giraph-tutorial/input

hadoop fs -mkdir -p /giraph-tutorial/output


git clone https://github.com/ffaghri1/cloudapp-giraph-tutorial.git


hadoop jar target/giraph-mp-1.0-SNAPSHOT-jar-with-dependencies.jar org.apache.giraph.GiraphRunner ConnectedComponentsComputation -vif org.apache.giraph.io.formats.IntIntNullTextInputFormat -vip /giraphtutorial/input/tiny2_graph.txt -vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat -op /giraph-tutorial/output/connected-components -w 1 -ca giraph.SplitMasterWorker=false


hadoop fs -cat /giraph-tutorial/output/connected-components/*

hadoop fs -get /giraph-tutorial/output/connected-components/* .

hadoop fs -rm -r -f /giraph-tutorial/output/connected-components/*



git clone -b release-1.1 https://github.com/apache/giraph.git



cd ~/giraph-tutorial/giraph
mvn -Phadoop_2 -Dhadoop.version=2.6.0 package -e -DskipTests=true

~/cloudapp-giraph-tutorial/giraph/giraph-core/target/giraph-1.1.0-for-hadoop-2.6.0-jar-with-dependencies.jar
~/cloudapp-giraph-tutorial/giraph/giraph-examples/target/giraph-examples-1.1.0-forhadoop-2.6.0-jar-with-dependencies.jar


ln -s ~/cloudapp-giraph-tutorial/giraph/giraph-core/target/giraph-1.1.0-forhadoop-2.6.0-jar-with-dependencies.jar giraph-core.jar

ln -s ~/cloudapp-giraph-tutorial/giraph/giraph-examples/target/giraph-examples-1.1.0-for-hadoop-2.6.0-jar-with-dependencies.jar giraph-examples.jar


[0,0,[[1,1],[3,3]]]
[1,0,[[0,1],[2,2],[3,1]]]
[2,0,[[1,2],[4,4]]]
[3,0,[[0,3],[1,1],[4,4]]]
10
[4,0,[[3,4],[2,4]]]


hadoop fs -put tiny_graph.txt /cloudapp-giraph-tutorial/input

"Shortest Path"

hadoop jar giraph-examples.jar org.apache.giraph.GiraphRunner org.apache.giraph.examples.SimpleShortestPathsComputation  -vif org.apache.giraph.io.formats.JsonLongDoubleFloatDoubleVertexInputFormat -vip /cloudapp-giraph-tutorial/input/tiny_graph.txt  -vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat -op /cloudapp-giraph-tutorial/output/shortestpaths -w 1 -ca giraph.SplitMasterWorker=false


hadoop fs -cat /giraph-tutorial/output/shortestpaths/part*
hadoop fs -get /giraph-tutorial/output/shortestpaths/part* .
hadoop fs -rm -r -f /giraph-tutorial/output/*


hadoop jar target/mp5-1.0-SNAPSHOT-jar-with-dependencies.jar 
org.apache.giraph.GiraphRunner ConnectedComponentsComputation 
-vif org.apache.giraph.io.formats.IntIntNullTextInputFormat 
-vip /mp5/data/graph.data -vof org.apache.giraph.io.formats.IdWithValueTextOutputFormat 
-op /mp5/output/part-a -w 1 
-ca giraph.SplitMasterWorker=false

Machine Library:
hadoop fs -mkdir -p /mllib-tutorial/input
hadoop fs -mkdir -p /mllib-tutorial/output

git clone https://github.com/ffaghri1/cloudapp-mllib-tutorial.git
cd cloudapp-mllib-tutorial/
hadoop fs -put data/mtcars.csv /mllib-tutorial/input
cd ~/cloudapp-mllib-tutorial
nano src/KMeansExample.java
mvn clean package
spark-submit --class KMeansExample target/mllib.mp-1.0-SNAPSHOT.jar 3 /mllib-tutorial/input/mtcars.csv
spark-submit --class KMeansExample target/mllib.mp-1.0-SNAPSHOT.jar 3 /mllib-tutorial/input/mtcars.csv 2> /dev/null

private static class ParsePoint implements Function<String, Vector> {
	private static final Pattern SPACE = Pattern.compile(",");
 	public Vector call(String line) {
		String[] tok = SPACE.split(line);
 		double[] point = new double[tok.length-1];
 		for (int i = 1; i < tok.length; ++i) {
 			point[i-1] = Double.parseDouble(tok[i]);
 		}
 		return Vectors.dense(point);
 	}
}

private static class ParseTitle implements Function<String, String> {
 private static final Pattern SPACE = Pattern.compile(",");
 public String call(String line) {
	 String[] tok = SPACE.split(line);
 	return tok[0];
 }
}


private static class PrintCluster implements VoidFunction<Tuple2<Integer, Iterable<String>>> {
 private KMeansModel model;
 public PrintCluster(KMeansModel model) {
	this.model = model;
 }

 public void call(Tuple2<Integer, Iterable<String>> Cars) throws Exception {
	String ret = "[";
	for(String car: Cars._2()){
		ret += car + ", ";
	}
	System.out.println(ret + "]");
 }
}


private static class ClusterCars implements PairFunction<Tuple2<String, Vector>, Integer, String> {
 private KMeansModel model;
 public ClusterCars(KMeansModel model) {
	 this.model = model;
 }
 public Tuple2<Integer, String> call(Tuple2<String, Vector> args) {
	String title = args._1();
	Vector point = args._2();
	int cluster = model.predict(point);
 	return new Tuple2<Integer, String>(cluster, title);
 }
}



 JavaRDD<String> lines = sc.textFile(inputFile);
 JavaRDD<Vector> points = lines.map(new ParsePoint());
 JavaRDD<String> titles = lines.map(new ParseTitle());
 KMeansModel model = KMeans.train(points.rdd(), k, iterations, runs, KMeans.RANDOM(), 0);
 JavaPairRDD<Integer, Iterable<String>> clusters =titles.zip(points).mapToPair(new
 ClusterCars(model)).groupByKey();
 clusters.foreach(new PrintCluster(model));


 spark-submit --class KMeansMP target/mp5-1.0-SNAPSHOT-jar-withdependencies.jar /mp5/data/cars.data /mp5/output/part-b/

	
 hadoop fs -cat /mp5/output/part-b

